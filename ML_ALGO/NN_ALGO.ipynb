{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set top level directory, path for reading feather and output file for the results\n",
    "top_wd = os.getcwd()\n",
    "feather_dir = top_wd + \"\\\\Feather\"\n",
    "os.makedirs(top_wd + \"\\\\Results\", exist_ok=True)\n",
    "results_dir = top_wd + \"\\\\Results\"\n",
    "holdout_dir = str(Path(top_wd).parents[0]) + \"\\\\AMELIA\\\\AMELIA_P_level_v0.2.3 (Person-Level)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for numeric conversion of sex variable\n",
    "def to_numeric(dataframe):\n",
    "    sex = {\"Male\":1,\"Female\":2}\n",
    "    dataframe = dataframe.replace({\"Sex\": sex})\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store Holdout set for testing\n",
    "os.chdir(holdout_dir)\n",
    "Holdout = feather.read_dataframe(\"Holdout.feather\") \n",
    "Holdout_y = Holdout[\"Person_Income\"]\n",
    "Holdout_x = Holdout.drop(columns = [\"index\", \"Person_Income\", \"Personal_ID\"])\n",
    "\n",
    "sc = StandardScaler()\n",
    "Holdout_x = to_numeric(Holdout_x)\n",
    "Holdout_unscaled = Holdout_x\n",
    "Holdout_x = sc.fit_transform(Holdout_x)\n",
    "Holdout_x = pd.DataFrame(Holdout_x, columns=Holdout_unscaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary for accesing all dataframes\n",
    "df_dict = {}\n",
    "for i in range(10):\n",
    "    os.chdir(feather_dir)\n",
    "    SRS = feather.read_dataframe(f\"0{i+1}_srs_sample.feather\") \n",
    "    Importance = feather.read_dataframe(f\"0{i+1}_importance_sample.feather\") \n",
    "    Synthetic = feather.read_dataframe(f\"0{i+1}_synthetic_sample.feather\")\n",
    "\n",
    "    #Apply numeric conversion (Male:1, Female:2)\n",
    "    SRS = to_numeric(SRS)\n",
    "    Importance = to_numeric(Importance)\n",
    "    Synthetic = to_numeric(Synthetic)\n",
    "\n",
    "    df_dict[f\"SRS_{i+1}\"] = SRS\n",
    "    df_dict[f\"Importance_{i+1}\"] = Importance\n",
    "    df_dict[f\"Synthetic_{i+1}\"] = Synthetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for handeling train test split\n",
    "def t_t_split(dataframe):\n",
    "    #Split x and y vars (also drop personal ID identifier and index)\n",
    "    x_var = dataframe.iloc[:,1:].drop(columns = [\"Personal_ID\", \"index\"])\n",
    "    y_var = dataframe.iloc[:,0]\n",
    "\n",
    "    #Creat Train/Test split for x and y\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_var, y_var, test_size = 0.25, random_state = 420)\n",
    "\n",
    "    #Keep a copy of unscaled x_test for later comparison\n",
    "    x_test_unscaled = x_test\n",
    "\n",
    "    #Scale x var for train and test\n",
    "    sc = StandardScaler()\n",
    "    #Done now for convience regarding column reassignment(rather than above when x_var created)\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.fit_transform(x_test)\n",
    "    x_train = pd.DataFrame(x_train, columns=x_var.columns)\n",
    "    x_test = pd.DataFrame(x_test, columns=x_var.columns)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, x_test_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through Sampling methods and run our NN on each one, storing the score and results\n",
    "def results(df_dict, Methods = \"All\"):\n",
    "   \"\"\"For Method pass: SRS, Importance or Synthetic (All Default)\"\"\"\n",
    "\n",
    "   s_names = [\"SRS\", \"Importance\", \"Synthetic\"]\n",
    "\n",
    "   scores = pd.DataFrame(columns = s_names)\n",
    "   scores_holdout = pd.DataFrame(columns = s_names)\n",
    "   predicts_dict = {}\n",
    "   holdout_p_dict = {}\n",
    "\n",
    "   \"\"\"I might try and make this a function so we can pass # of runs and one method instead of all methods\"\"\"\n",
    "   if Methods == \"All\":\n",
    "      for Method in s_names:\n",
    "         for i in range(10):   \n",
    "            x_train, x_test, y_train, y_test, x_test_unscaled = t_t_split(df_dict[f\"{Method}_{i+1}\"])\n",
    "\n",
    "            #Run Multi-layer Perceptron regressor\n",
    "            regr = MLPRegressor(random_state=420, max_iter=500, activation = \"relu\", solver='lbfgs').fit(x_train, y_train)\n",
    "            \n",
    "            \"\"\"Write a scoring and predictions function for holdout set\"\"\"\n",
    "            #Generate Score Value\n",
    "            s_v = regr.score(x_test, y_test)\n",
    "            h_s_v = regr.score(Holdout_x, Holdout_y)\n",
    "\n",
    "            #Add score to scores DataFrame\n",
    "            if Method == \"SRS\":\n",
    "               scores = scores.append({Method:s_v}, ignore_index=True)\n",
    "               scores_holdout = scores_holdout.append({Method:h_s_v}, ignore_index=True)\n",
    "\n",
    "            #Once SRS is done, scores are updated with this function (To avoid indexing errors) \n",
    "            if Method != \"SRS\":\n",
    "               scores.loc[i,f\"{Method}\"] = s_v\n",
    "               scores_holdout.loc[i,f\"{Method}\"] = h_s_v\n",
    "\n",
    "            #Generate Predictions\n",
    "            predictions = regr.predict(x_test)\n",
    "            holdout_p = regr.predict(Holdout_x)\n",
    "            \n",
    "            #Replace negative outputs with 0\n",
    "            predictions = np.where(predictions < 0, 0, predictions)\n",
    "            holdout_p = np.where(holdout_p < 0, 0, holdout_p)\n",
    "\n",
    "            #Convert Predicitons from Ndarray to Dataframe for Concat\n",
    "            predictions = pd.DataFrame(data=predictions, columns=[\"Predictions\"])\n",
    "            holdout_p = pd.DataFrame(data=holdout_p, columns=[\"Predictions\"])\n",
    "            \n",
    "            #Store Y_test, Predictions for X_test and data for X_test (For Comparision)\n",
    "            fused_df = pd.concat([y_test.reset_index(drop=True), predictions, x_test_unscaled.reset_index(drop=True)], axis = 1)\n",
    "            fused_h_df = pd.concat([Holdout_y.reset_index(drop=True), holdout_p, Holdout_unscaled.reset_index(drop=True)], axis = 1)\n",
    "            predicts_dict[f\"{Method}_{i+1}\"] = fused_df\n",
    "            holdout_p_dict[f\"{Method}_{i+1}\"] = fused_h_df\n",
    "                  \n",
    "   return scores, predicts_dict, scores_holdout, holdout_p_dict\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime for SRS: 49 minutes, 25 seconds\n",
    "scores, predicts_dict, scores_holdout, holdout_p_dict = results(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(results_dir)\n",
    "scores.index += 1\n",
    "scores_holdout.index += 1\n",
    "feather.write_dataframe(scores,\"scores.feather\")\n",
    "feather.write_dataframe(scores_holdout,\"scores_holdout.feather\")\n",
    "for i in range(10):\n",
    "    feather.write_dataframe(predicts_dict[f\"SRS_{i+1}\"],f\"0{i+1}_SRS_MLPR_results.feather\") \n",
    "    feather.write_dataframe(holdout_p_dict[f\"SRS_{i+1}\"],f\"0{i+1}_SRS_Holdout_results.feather\") \n",
    "    feather.write_dataframe(predicts_dict[f\"Importance_{i+1}\"],f\"0{i+1}_Importance_MLPR_results.feather\") \n",
    "    feather.write_dataframe(holdout_p_dict[f\"Importance_{i+1}\"],f\"0{i+1}_Importance_Holdout_results.feather\") \n",
    "    feather.write_dataframe(predicts_dict[f\"Synthetic_{i+1}\"],f\"0{i+1}_Synthetic_MLPR_results.feather\")\n",
    "    feather.write_dataframe(holdout_p_dict[f\"Synthetic_{i+1}\"],f\"0{i+1}_Synthetic_Holdout_results.feather\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c14cf6fee9e82c9cdd34ec15f18624274457bb0e780094f6e02ebebdc5a43f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('amelia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
